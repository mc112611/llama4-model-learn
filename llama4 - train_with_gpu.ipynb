{"cells":[{"cell_type":"code","execution_count":1,"id":"86d72aab","metadata":{"id":"86d72aab","executionInfo":{"status":"ok","timestamp":1746490670603,"user_tz":-480,"elapsed":8848,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 导包\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dataclasses import dataclass"]},{"cell_type":"code","execution_count":2,"id":"595b7bc3","metadata":{"id":"595b7bc3","executionInfo":{"status":"ok","timestamp":1746490670605,"user_tz":-480,"elapsed":23,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["@dataclass\n","class Llama4TextConfig:\n","    vocab_size: int = 202048  # 词表大小（包含所有token的数量）\n","    hidden_size: int = 5120  # 隐藏层维度（也即token embedding的维度）\n","    intermediate_size: int = 8192  # 注意力模块中的中间维度（如用于RMSNorm等）\n","    intermediate_size_mlp: int = 16384  # MLP模块的中间层维度\n","    num_hidden_layers: int = 48  # Transformer block 的层数\n","    num_attention_heads: int = 40  # 注意力头的数量\n","    num_key_value_heads: int = 8  # KV-head 的数量（可小于attention head数量，表示采用multi-query attention）\n","    head_dim: int = 128  # 每个注意力头的维度\n","    max_position_embeddings: int = 4096 * 32  # 最大位置编码长度（支持的最大token序列长度）\n","    rms_norm_eps: float = 1e-5  # RMSNorm中的epsilon值，防止除以0\n","    pad_token_id: int = 200018  # padding token 的ID\n","    bos_token_id: int = 1  # 序列开始（Begin Of Sequence）token 的ID\n","    eos_token_id: int = 2  # 序列结束（End Of Sequence）token 的ID\n","    rope_theta: float = 500000  # RoPE位置编码中的 theta 参数（值越大，支持的序列长度越长）\n","    attention_dropout: float = 0.0  # 注意力模块中的dropout比例（通常在inference时为0）\n","    num_experts_per_tok: int = 1  # 每个token选中的专家数量（MoE中 Top-K 的K值）\n","    num_local_experts: int = 16  # 每个MoE层中包含的专家数量\n","    use_qk_norm: bool = True  # 是否对 QK 做归一化处理（影响注意力权重分布）\n","    no_rope_layer_interval: int = 4  # 每隔多少层不使用RoPE（控制位置编码插入的层间距）\n","    attention_chunk_size: int = 8192  # 用于大模型推理时的注意力分块大小（节省显存）\n","    attn_temperature_tuning: float = 4  # 注意力温度调整因子，用于调节softmax的分布平滑程度\n","    floor_scale: int = 8192  # 温度缩放的最小尺度（影响softmax的归一化）\n","    attn_scale: float = 0.1  # 注意力得分的缩放因子，通常用于调节softmax前的qk dot product结果"]},{"cell_type":"markdown","id":"8e84c14a","metadata":{"id":"8e84c14a"},"source":["## 构造MOE模块"]},{"cell_type":"markdown","id":"f79a194f","metadata":{"id":"f79a194f"},"source":["### 创建MOE的专家对象"]},{"cell_type":"code","execution_count":3,"id":"8c0ad750","metadata":{"id":"8c0ad750","executionInfo":{"status":"ok","timestamp":1746490670606,"user_tz":-480,"elapsed":23,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["class Llama4TextExperts(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Llama4TextExperts, self).__init__()\n","\n","        # 专家数量\n","        self.num_experts = config.num_local_experts\n","        # 前馈全连接中间层维度大小\n","        self.intermediate_size = config.intermediate_size\n","        # 隐藏层维度\n","        self.hidden_size = config.hidden_size\n","        # 专家维度，与FFN层维度统一\n","        self.expert_dim = config.intermediate_size\n","\n","        # 下面三行是MOE的MLP部分，用来实现激活函数前后的线性变换，由于激活函数是将线型变为非线性。\n","        # gate_up_proj是一个输入数据的加工（专业说法叫上投影层），用nn.Parameter告诉pytorch这是一个可以训练的权重，创建一个没有初始化数值的张量，形状为：[专家数量,隐藏层维度，2倍的专家嵌入维度]\n","        # 之所以是2倍，因为这一层，我们需要计算两个不同的输出向量：一个是“值（value）”，一个是“门（gate）”。其中gate用于判断，value用于计算。\n","        self.gate_up_proj = nn.Parameter(torch.empty(self.num_experts, self.hidden_size, 2*self.expert_dim))\n","        # down_proj是下投影层，用于把上投影层加工的结果变回原始维度的大小，方便后续处理\n","        self.down_proj = nn.Parameter(torch.empty(self.num_experts, self.expert_dim, self.hidden_size))\n","        # 一个激活函数，门控结构，用于过滤，让输出更加平滑。也用于线型神经网络变为非线性，能够处理复杂问题\n","        self.act_fn = nn.SiLU()\n","\n","        # 对上投影层和下投影层做初始化，使用正态分布。\n","        nn.init.normal_(self.gate_up_proj)\n","        nn.init.normal_(self.down_proj)\n","\n","    def forward(self, hidden_states):\n","\n","        # 原作者注释：\n","        ### Hidden States we Pass in Here are already Sorted (according to the logic explained in Llama4TextMoe) ###\n","        ### Go Ahead and Split the Num Experts and Num Tokens Dimension Up (Num Experts x Num Tokens x Embed Dim) ###\n","\n","        # 个人注释：\n","        # 调整数据形状变为：(num_experts, num_tokens, hidden_size)\n","        hidden_states = hidden_states.reshape(self.num_experts, -1, self.hidden_size)\n","\n","        #原作者注释：\n","        ### Now Multiply All our Tokens (copied for each Expert) by each Expert Embeddings ###\n","        ### gate_up_proj: (Num Experts x Hidden Size x 2*Expert Dim) ###\n","        ### gate_up -> (Num Experts x Num Tokens x 2*Expert Dim)\n","\n","        # 使用“数据加工——gate_up_proj” 对当前输入的隐藏层状态进行“加工”，加工方法为批矩阵乘法\n","        gate_up = torch.bmm(hidden_states, self.gate_up_proj)\n","        # 原作者注释：\n","        ### The reason our linear layer was 2*Expert Dim output was because we do a gated linear layer\n","        ### just like you find in previous Llama implementations\n","        ### First lets go ahead and chunk on the final dimension so we get two tensors:\n","        ### gate -> (Num Experts x Num Tokens x Expert Dim)\n","        ### up -> (Num Experts x Num Tokens x Expert Dim)\n","\n","        #个人注释：\n","        # 将gate_up矩阵，在最后一个维度拆分成2份。  之前的 2*self.expert_dim ，现在拆成2等份，每一份最后一个维度为expert_dim。对应gate和value\n","        gate, up = gate_up.chunk(2, dim=-1)\n","\n","        # 原作者注释：\n","        ### Apply the Activation Function to Up (the SiLU activation) and multiply to gate\n","        ### Effectively giving finer control over what information continues and what doesnt\n","        ### gated -> (Num Experts x Num Tokens x Expert Dim)\n","\n","        # 个人注释：\n","        # 变量gate是门控信息，up里是实际内容。    这里是先将gate信息经过激活函数变为非线性，然后按元素与up中的值做乘法。\n","        gated = up * self.act_fn(gate)\n","        # 原作者注释：\n","        ### Now Finally Projec the Expert Dim back down to the hidden size using Down Proj ###\n","\n","        #个人注释：\n","        # 用下投影层将处理过的内容还原，方便后续处理，执行分块矩阵相乘，这样原始数据张量便带有了专家门控信息。\n","        next_states = torch.bmm(gated, self.down_proj)\n","        # 原作者注释：\n","        ### Flatten from (Num Experts x Num Tokens x Embed Dim) -> (Num Experts*Num Tokens x Embed Dim) ###\n","\n","        #个人注释：\n","        # 原作者注释写的很清楚，改变最终单个专家输出的形状：(Num Experts x Num Tokens x Embed Dim) -> (Num Experts*Num Tokens x Embed Dim)\n","        next_states = next_states.view(-1,self.hidden_size)\n","\n","        return next_states"]},{"cell_type":"code","execution_count":4,"id":"146a9ab9","metadata":{"id":"146a9ab9","executionInfo":{"status":"ok","timestamp":1746490670668,"user_tz":-480,"elapsed":66,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# LLaMa的共享专家层。减小计算开销，对输入进行统一处理。\n","# 共享专家负责统一处理所有的输入，执行固定的计算：门控线性变换 -> 上投影 -> 非线性激活 ->下投影\n","# 共享专家输出的数据形状，与输入是一样的\n","class Llama4TextMLP(nn.Module):\n","\n","    def __init__(self, config):\n","\n","        \"\"\"\n","        Exactly the same as the Llama4TextExperts, but this is a single MLP layer. In\n","        Llama4 they pass tokens to both an MOE and a single MLP and add the results\n","        \"\"\"\n","\n","        super(Llama4TextMLP, self).__init__()\n","\n","        self.config = config\n","        self.gate_proj = nn.Linear(config.hidden_size, config.intermediate_size, bias=False)\n","        self.up_proj = nn.Linear(config.hidden_size, config.intermediate_size, bias=False)\n","        self.down_proj = nn.Linear(config.intermediate_size, config.hidden_size, bias=False)\n","        self.activation_fn = nn.SiLU()\n","\n","    def forward(self, x):\n","        gated = self.activation_fn(self.gate_proj(x)) * self.up_proj(x)\n","        return self.down_proj(gated)"]},{"cell_type":"code","execution_count":5,"id":"8fc68704","metadata":{"id":"8fc68704","executionInfo":{"status":"ok","timestamp":1746490670679,"user_tz":-480,"elapsed":29,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 构建LLama4的MOE层\n","class Llama4TextMoe(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Llama4TextMoe, self).__init__()\n","\n","        self.top_k = config.num_experts_per_tok\n","        self.hidden_dim = config.hidden_size\n","        self.num_experts = config.num_local_experts\n","        self.experts = Llama4TextExperts(config)\n","        self.router = nn.Linear(config.hidden_size, config.num_local_experts, bias=False)\n","        self.shared_expert = Llama4TextMLP(config)\n","\n","    def forward(self, hidden_states):\n","        # [batch_size, seq_len, embed_dim]，比如是 [2, 128, 4096] 表示有两个句子，每个句子 128 个词，每个词用 4096 维的向量表示。\n","        batch_size, seq_len, embed_dim = hidden_states.shape\n","\n","        ### Flatten Batch and Seq_Len Dimensions so we have (Num Tokens x Embed Dim) ###\n","        # 转换数据形状，将输入数据的隐藏层向量变为 ：Num Tokens x Embed Dim\n","        hidden_states = hidden_states.view(-1, self.hidden_dim)\n","\n","        ### Get Expert Index for Each Token (Num Tokens x Num Experts) ###\n","        # 用一个线性层，对输入的隐藏层数据进行打分，确定当前输入的数据更适合哪个“专家”，线性层输出为：专家数量num_local_experts\n","        router_logits = self.router(hidden_states)    # 路由器选择专家\n","\n","        ### Now we want each token to go to its own expert, but to parallize this easily we can do the following:\n","        ### Step 1: Lets pretend each expert will get ALL TOKENS ###\n","        # 第一步：假设每个专家都会获得所有的token，全部token数tokens_per_expert\n","        tokens_per_expert = batch_size * seq_len\n","\n","        ### Step 2: Get the topK experts for each token (from our router logits)\n","        ### this gives:\n","        ###     router_top_value: The logit from our router logits sorted for each token from largest to smallest (upto k of them)\n","        ###     router_indices: The indexes of which expert had the largest logit to smallest (upto k of them)\n","\n","        # 将路由器输出的结果，即16个专家，选择top_k个进行激活，输出结果为：router_top_value代表最大得分的数值，router_indices最大得分对应的是哪两个专家的索引\n","        router_top_value, router_indices = torch.topk(router_logits, self.top_k, dim=1)\n","\n","        ### Step 3: Create a Matrix of -infinity in the shape of (Num Tokens x Num Experts)\n","        ### Fill this matrix at the indexes of the topk experts selected by the router for each token with the logits for those k experts\n","        ### Basically makes sure we have -inf for the non topk tokens and its router logit otherwise!\n","        ### And go ahead and transpose this matrix so it finally becomes as (Num Experts x Num Tokens)\n","\n","        # 创建一个和router_logits一样大的矩阵，内容填充为负无穷，表示：默认所有专家都不被选中，使用scatter将矩阵中的部分位置，替换成 Top-K 专家的分数。索引为router_indices，值为router_top_value\n","        # 之后进行一次转置，因为当前是每一列代表一个序列。我们将其转置变为每一行为一个句子序列，代表每个token的专家得分\n","        router_scores = torch.full_like(router_logits, float(\"-inf\")).scatter_(dim=1, index=router_indices, src=router_top_value).transpose(0,1)\n","\n","        ### Step 4: Because we are passing in \"ALL TOKENS\" to every expert, lets update our router indicies to be\n","        ### indexes from 0 to NUM TOKENS, repeated for EVERY Expert! It will something like:\n","\n","        ### [0, 1, 2, ..., Num Tokens]\n","        ### [0, 1, 2, ..., Num Tokens]\n","        ### [0, 1, 2, ..., Num Tokens]\n","        ### ...\n","\n","        ### Repeating the number of rows for the number of experts we have!\n","\n","        # 首先创建一个一维数组，用来表示每个token的编号，类似于：[0, 1, 2, ..., num_tokens - 1] ，tokens_per_expert = batch_size * seq_len，就是 token 的总数量\n","        # 把一维数组变为二维：[[0, 1, 2, ..., num_tokens - 1]]\n","        # 让这个数组复制 num_experts 行.\n","        # 因为我们下一步要把 hidden_states 中所有 token 的 embedding，复制一份给每个专家。N 个 token，每个专家都要获得这 N 个 token 的编号，用来复制取出数据。\n","\n","        router_indices = torch.arange(tokens_per_expert, device=hidden_states.device).unsqueeze(0).expand(router_scores.size(0), -1)\n","\n","        ### Step 5: Now when we grab our embeddings with these indexes, we have the embedding dimension as well. Our Data is the shape\n","        ### of (Num Tokens x Embed Dim) Lets go ahead and flatten our router indicies, add a dimension for the embed dim and repeat.\n","        ### This means we will end with a (Num_Experts*Num_tokens x Embed Dim) Matrix at the end.\n","\n","        # 之前我们拿到二维的token索引矩阵：[num_experts, num_tokens]\n","        # 现在，每一个 token 的索引，要扩展成 [hidden_dim] 个维度，用来一次性 gather 所有 embedding 维度上的数据\n","        # 我们需要让 router_indices 的形状变成 [num_experts * num_tokens, hidden_dim]\n","        router_indices = router_indices.reshape(-1,1).expand(-1, self.hidden_dim)\n","\n","        ### Step 6: Update our Router Scores to be between 0 and 1. All our non topk scores (that are currently -inf) will become 0!\n","        # 将router_scores中的值经过sigmoid激活函数，负无穷变为0，其他值变为0~1之间的值，再将张量统一一下浮点数精度。\n","        router_scores = torch.sigmoid(router_scores.float()).to(hidden_states.dtype)\n","\n","        ### Step 7: Gather All Our Hidden States By our router_indices (repeating all tokens for each Expert!)\n","\n","        # gather是一个根据索引去获取值的函数，需要学习一下。在这里，主要是通过index，专家路由器给出的索引，在input（hidden_states）的第一个维度，取数据。\n","        # 相当于，所有的专家通过这一步才是拿到token的内容。\n","        routed_in = torch.gather(\n","            input=hidden_states,\n","            dim=0,\n","            index=router_indices\n","        )\n","\n","        ### Step 8: We now have repeated all our token embeddings for every expert. But we only want to keep the experts that\n","        ### were in our TopK. Well, we hav eour router_scores that is 0 for non Topk expert indicies. We can therefore go\n","        ### ahead and multiply, as it will 0 out our embeddings assigned to a an expert that was not in its TopK\n","        ### This also multiplies the embeddings from their topk experts by the weights assigned by the router\n","\n","        ### router_scores -> (Num Experts x Num Tokens)\n","        ### routed_in -> (Num Experts*Num Tokens x Embed Dim)\n","\n","        # routed_in形状：[num_experts * num_tokens, hidden_dim]\n","        # 将router_scores的形状，从[num_experts, num_tokens] 变为 [num_experts * num_tokens, 1]\n","        # 然后按元素相乘（加权）\n","        # 最终结果是对routed_in的内容，保留重要的token信息，抑制不重要的信息\n","        routed_in = routed_in * router_scores.reshape(-1, 1)\n","\n","        ### Lets Pass this to our Experts!! ###\n","        ### routed_out -> (Num_Experts*Num_Tokens x Embed Dim)\n","\n","        # 将处理好的数据，输入进专家。\n","        # 当routed_in输入进专家模型，发生了什么：self.experts 将根据每个 token 对应的专家模型进行处理。每个专家（专家模型）会处理它接收到的 token 数据，产生一个输出。这些专家是并行的，处理不同 token 数据时具有不同的能力和权重。\n","        # routed_out 是一个新的 tensor，包含了经过所有专家模型处理后的 token 数据。它的形状通常是 [num_experts * num_tokens, hidden_dim]，和 routed_in 一样，因为每个 token 对应多个专家输出\n","        routed_out = self.experts(routed_in)\n","\n","        ### Similary, pass our Hidden States to the Shared Expert ###\n","        ### In Llama4 we have both Experts and a shared expert ###\n","        ### and we add the results together at the end! ###\n","        ### shared_expert_out -> (Num_Tokens x Embed Dim)\n","\n","        # 经过共享专家MLP层处理\n","        # 这里hidden_states的形状为：[batch_size * seq_len, hidden_dim]     是将batch_size中所有token合并成一个大的token表。每个token包含embedding信息。\n","        shared_expert_out = self.shared_expert(hidden_states)\n","\n","        ### Now we Add our Results Together! But we have a bit of a challenge ###\n","        ### routed_out repeats all tokens for all experts (but we zeroed out the experts that were not topk for each token)\n","        ### shared_expert_out is just our projection for all the tokens.\n","        ### If we want to add our shared_expert_out to our routed_outs, we just need to grab the correct indicies from our\n","        ### routed_outs that coorespond to the correct experts for each token, and then add it all together!\n","\n","        ### REMEMBER: The output of Tokens (when passed to their Non-Topk expert) will just be 0!\n","        ### We are basically going through every experts output here and adding their outputs each expert\n","        ### to our shared_expert_out. But because there are lots of zeros in our embeddings from each\n","        ### expert (if that was not a topk expert), we are basically accumulating across all the tokens\n","\n","        ### This is the same as just for looping through all the expert outputs and adding it to our\n","        ### shared_expert_out, but this is a oneliner that does that same thing!\n","\n","        ### Take a look at scatter_add_ if you want more details!\n","        ### https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_\n","\n","\n","\n","        # shared_expert_out -> [num_tokens, hidden_dim]\n","        # routed_out -> [num_experts * num_tokens, hidden_dim]\n","        # 我们要把每个专家处理出来的结果（routed_out），累加 到对应的 token 上，也就是 shared_expert_out[token_idx] += routed_out[i]\n","        # 用for循环是这样写：\n","        # for i in range(routed_out.size(0)):\n","        #     idx = router_indices[i]\n","        #     shared_expert_out[idx] += routed_out[i]\n","\n","        # 假设每个专家有自己擅长的领域，router会给每个token分配到top_k个专家，每个专家都会返回一个向量（代表每个专家的理解），将这些专家给出的向量结果累加起来，就是输入内容的最终向量表示。\n","        # 因为每个专家擅长领域不同，并且只选top_k个专家去处理，会漏掉一部分信息，而共享专家会将所有内容进行计算，因此共享专家用来修正top_k个专家给出的结果。因此要加上共享专家输出的结果。\n","        shared_expert_out.scatter_add_(dim=0, index=router_indices, src=routed_out)\n","\n","        return shared_expert_out"]},{"cell_type":"markdown","id":"c2e5dfd2","metadata":{"id":"c2e5dfd2"},"source":["## 旋转位置编码器"]},{"cell_type":"code","execution_count":6,"id":"b2a93122","metadata":{"id":"b2a93122","executionInfo":{"status":"ok","timestamp":1746490670680,"user_tz":-480,"elapsed":3,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["class Llama4TextRotaryEmbedding(nn.Module):\n","\n","    def __init__(self, config, device=None):\n","        super(Llama4TextRotaryEmbedding, self).__init__()\n","\n","        # 保存最大支持的位置长度   KVcache\n","        self.max_seq_len_cached = config.max_position_embeddings\n","        # 初始最大序列长度\n","        self.original_max_seq_len = config.max_position_embeddings\n","\n","        self.config = config\n","\n","        # 旋转位置编码器所需要的频率值\n","        inv_freq = self._compute_default_rope_parameters(self.config, device=device)\n","        # 将这个频率值注册进模型结构中，而不是作为一个变量。\n","        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n","\n","    # 计算旋转角频率\n","    def _compute_default_rope_parameters(self, config, device):\n","\n","        base = config.rope_theta\n","        head_dim = config.head_dim\n","\n","\n","        inv_freq = 1.0 / (base ** (torch.arange(0, head_dim, 2, dtype=torch.int64).to(device=device, dtype=torch.float) / head_dim))\n","\n","        return inv_freq\n","\n","    @torch.no_grad()\n","    def forward(self, x, position_ids):\n","\n","        ### x is our data (Batch x Seq Len x ) ###\n","        ### position_ids is the position index of every token (Batch x Seq Len) ###\n","\n","        ### Our inv_freq is a vector of length (Hidden Dim/2). Lets add dimensions and repeat batch size number of times\n","        ### inv_freq_expanded -> (Batch x Hidden_Dim/2 x 1)\n","        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1).to(x.device)\n","\n","        ### Our position ids is just Batch x Seq Len, add a new dimension to make it (Batch x 1 x Seq Len)\n","        position_ids_expanded = position_ids[:, None, :].float()\n","\n","        ### Now We can compute our freqs for all positions (by multiplying by the position index) ###\n","        ### (B x H/2 X 1) @ (B x 1 x L) -> (B x H/2 x L)\n","\n","        with torch.autocast(device_type=x.device.type, enabled=False):\n","            # 计算旋转角度（采样频率），广播成(B x H/2 x L)的形状\n","            freqs = (inv_freq_expanded @ position_ids_expanded)\n","\n","            ### Now make sure Freqs is (B x L x H/2) by transpose ###\n","            # 转置成 (B x L x H/2) 的形状\n","            freqs = freqs.transpose(1,2)\n","\n","            ### Convert Frequencies to complex (polar) representations (with magnitude 1)###\n","            # 生成复数形式的旋转位置编码\n","            freqs_cis = torch.polar(abs=torch.ones_like(freqs), angle=freqs)\n","\n","        return freqs_cis"]},{"cell_type":"code","execution_count":7,"id":"a61955cf","metadata":{"id":"a61955cf","executionInfo":{"status":"ok","timestamp":1746490670695,"user_tz":-480,"elapsed":8,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 将复数的旋转位置编码器，注入到q和k张量中\n","def apply_rotary_emb(xq, xk, freqs_cis):\n","\n","    ### We want to \"rotate\" every consecutive pair along the embedding dimension ###\n","    ### by our freqs_cis, Lets first split them up! ###\n","    ### xq_split -> (B x Seq_len x Num Heads x Embed_dim/2 x 2)\n","    ### xk_split -> (B x Seq_len x Num Heads x Embed_dim/2 x 2)\n","\n","    # 老规矩，将注意力机制的Q和K在最后一个维度进行分成两两一对儿。\n","    # 假设xq原本为：xq.shape 形状为(2, 3, 4, 8)，对应(batch,seq_len,num_heads,dim)，变成(batch,seq_len,num_heads,dim/2,2)。也就是(2,3,4,4,2)\n","    # 最后一个维度形状变化：[e0, e1, e2, e3, e4, e5, e6, e7] -> [e0, e1], [e2, e3], [e4, e5], [e6, e7]\n","\n","    xq_split = xq.float().reshape(*xq.shape[:-1], -1, 2)\n","    xk_split = xk.float().reshape(*xk.shape[:-1], -1, 2)\n","\n","    ### Now rotating with a complex number is the same as mulitplying (phase shift) ###\n","    ### take a look here for rotation property: https://wumbo.net/concepts/complex-number-system/ ###\n","    ### technically multiplying also scales, but we made sure our freqs_cis was magnitude 1 ###\n","    ### Problem: xq_split and xk_split are currently real numbers. Lets check what we wanted to do.\n","    ### Lets go along the embedding dim for one token:\n","    ### [e0, e1, e2, e3, e4, e5, e6, e7, e8, ...]\n","    ### We have gone ahead and chunked it like the following:\n","    ### [e0, e1]\n","    ### [e2, e3]\n","    ### [e4, e5]\n","    ### [e6, e7]\n","    ### ....\n","\n","    ### And now we want to rotate each of these 2dim vector by our complex freqs_cis. To do this correctly,\n","    ### These 2dim vectors must also be complex so we can convert them to complex numbers like the following:\n","    ### [e0+j*e1]\n","    ### [e2+j*e3]\n","    ### [e4+j*e5]\n","    ### [e6+j*e7]\n","    ### ....\n","\n","    ### xq_split -> (B x Seq_len x Num Heads x Embed_dim/2) # Complex number used the 2 dimension from earlier\n","    ### xk_split -> (B x Seq_len x Num Heads x Embed_dim/2) # Complex number used the 2 dimension from earlier\n","\n","    # 将q和k转换成复数：[e0 + i·e1], [e2 + i·e3], ...\n","    xq_split = torch.view_as_complex(xq_split)\n","    xk_split = torch.view_as_complex(xk_split)\n","\n","    ### Now Go Ahead and Multiply with our freqs (adding extra dimension for attention heads) !\n","    # 使用复数乘法，将q和k与之前的旋转位置编码进行按元素计算\n","    xq_out = xq_split * freqs_cis[:, :, None, :]\n","    xk_out = xk_split * freqs_cis[:, :, None, :]\n","\n","    ### Now that we have done our Rotary embeddings with complex numbers, go ahead and return back to real numbers ###\n","    ### xq_out -> (B x Seq_len x Num Heads x Embed_dim/2 x 2) # Convert to real gave that 2 dimension back\n","    ### xk_out -> (B x Seq_len x Num Heads x Embed_dim/2 x 2) # Convert to real gave that 2 dimension back\n","\n","    # 再把复数转换成普通实数。\n","    xq_out = torch.view_as_real(xq_out)\n","    xk_out = torch.view_as_real(xk_out)\n","\n","    ### Flatten Embed_dim/2 x 2 dimensions back to Embed_dim\n","\n","    # 还原之前的维度变换，也就是 （2，3，4，4，2） -> （2，3，4，8）\n","    xq_out = xq_out.flatten(3)\n","    xk_out =xk_out.flatten(3)\n","\n","    # 输出覆盖了旋转位置编码器的 q和k，并确保数据类型与输入相同。\n","    return xq_out.type_as(xq), xk_out.type_as(xk)"]},{"cell_type":"code","execution_count":8,"id":"9aa051a9","metadata":{"id":"9aa051a9","executionInfo":{"status":"ok","timestamp":1746490670703,"user_tz":-480,"elapsed":7,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 构造一个L2归一化的模块\n","class Llama4TextL2Norm(torch.nn.Module):\n","    def __init__(self, eps=1e-6):\n","        super().__init__()\n","        self.eps = eps\n","\n","    def _norm(self, x):\n","\n","        ### We want to do x / sqrt((x**2).mean()) along the last dimension! ###\n","        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n","\n","    def forward(self, x):\n","        return self._norm(x.float()).type_as(x)\n","\n","    def extra_repr(self):\n","        return f\"eps={self.eps}\""]},{"cell_type":"code","execution_count":9,"id":"60206a74","metadata":{"id":"60206a74","executionInfo":{"status":"ok","timestamp":1746490670731,"user_tz":-480,"elapsed":27,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 构造一个RMSNorm模块，输入为隐藏层维度\n","class Llama4TextRMSNorm(nn.Module):\n","    def __init__(self, hidden_size, eps=1e-5):\n","\n","        super().__init__()\n","        self.eps = eps\n","        self.weight = nn.Parameter(torch.ones(hidden_size))\n","\n","    def _norm(self, x):\n","        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n","\n","    def forward(self, x):\n","        output = self._norm(x.float()).type_as(x)\n","        return output * self.weight\n","\n","    def extra_repr(self):\n","        return f\"{tuple(self.weight.shape)}, eps={self.eps}\""]},{"cell_type":"code","execution_count":10,"id":"a094865a","metadata":{"id":"a094865a","executionInfo":{"status":"ok","timestamp":1746490670745,"user_tz":-480,"elapsed":2,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# KV cache层\n","class Cache:\n","    \"\"\"\n","    KV Cache Method that is close to the Huggingface DynamicCache\n","    https://github.com/huggingface/transformers/blob/main/src/transformers/cache_utils.py\n","    \"\"\"\n","\n","    def __init__(self, config):\n","\n","        ### Counter for Number of Tokens in Cache ###\n","        # 缓存的token数量（计数器）\n","        self._seen_tokens = 0\n","\n","        ### Key/Value Cache (List of Tensor, where list is over model layers) ###\n","        self.key_cache = [torch.tensor([]) for _ in range(config.num_hidden_layers)]\n","        self.value_cache = [torch.tensor([]) for _ in range(config.num_hidden_layers)]\n","\n","    def __repr__(self):\n","        return f\"DyanmicCache(Num_Layers: {len(self.key_cache)} | Cached Tokens: {self.key_cache[0].shape[2]})\"\n","\n","    def update(self, key_states, value_states, layer_idx):\n","\n","        ### Only iterate num tokens seen on the first layer ###\n","        ### key_states (B x H x L x E)\n","        ### value_states (B x H x L x E)\n","\n","        # 形状为：(batch_size, num_heads, seq_len, head_dim)\n","\n","        if layer_idx == 0:\n","            # key_states的倒数第二个元素是seq_len\n","            self._seen_tokens += key_states.shape[-2]\n","\n","        ### Append New key/Value states to key/value cache ###\n","        # 将新的key_states和value_chache添加到缓存中。 torch.cat是沿着指定维度进行拼接。  这里是沿着seq_len进行拼接\n","        self.key_cache[layer_idx] = torch.cat([self.key_cache[layer_idx], key_states], dim=-2)\n","        self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], value_states], dim=-2)\n","\n","        # 返回更新后的缓存\n","        return self.key_cache[layer_idx], self.value_cache[layer_idx]\n","\n","    # 该函数用于返回指定层ID的序列长度（seq_len），如果KVcache为空，则返回0\n","    def get_seq_len(self, layer_idx=0):\n","        return self.key_cache[layer_idx].shape[-2] if self.key_cache[layer_idx].numel() != 0 else 0"]},{"cell_type":"markdown","id":"d042cfd6","metadata":{"id":"d042cfd6"},"source":["## LLama4注意力机制实现"]},{"cell_type":"code","execution_count":11,"id":"38610c9d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38610c9d","executionInfo":{"status":"ok","timestamp":1746490670752,"user_tz":-480,"elapsed":6,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"a5e71f6a-a86c-4eac-9159-945a3411066f"},"outputs":[{"output_type":"stream","name":"stdout","text":["['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'attention_chunk_size', 'attention_dropout', 'attn_scale', 'attn_temperature_tuning', 'bos_token_id', 'eos_token_id', 'floor_scale', 'head_dim', 'hidden_size', 'intermediate_size', 'intermediate_size_mlp', 'max_position_embeddings', 'no_rope_layer_interval', 'num_attention_heads', 'num_experts_per_tok', 'num_hidden_layers', 'num_key_value_heads', 'num_local_experts', 'pad_token_id', 'rms_norm_eps', 'rope_theta', 'use_qk_norm', 'vocab_size']\n"]}],"source":["a=Llama4TextConfig()\n","print(dir(a))"]},{"cell_type":"code","execution_count":12,"id":"c893d92b","metadata":{"id":"c893d92b","executionInfo":{"status":"ok","timestamp":1746490670784,"user_tz":-480,"elapsed":31,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["class Llama4TextAttention(nn.Module):\n","    def __init__(self, config, layer_idx):\n","        super(Llama4TextAttention, self).__init__()\n","\n","        self.config = config\n","        self.layer_idx = layer_idx\n","        self.head_dim = config.head_dim\n","        self.num_attention_heads = config.num_attention_heads\n","        self.num_key_value_groups = config.num_attention_heads // config.num_key_value_heads\n","        self.num_key_value_heads = config.num_key_value_heads\n","        self.scaling = self.head_dim **-0.5\n","        self.attn_scale = config.attn_scale\n","        self.floor_scale = config.floor_scale\n","        self.attn_temperature_tuning = config.attn_temperature_tuning\n","        self.attention_dropout = config.attention_dropout\n","        self.is_causal = True\n","        self.use_rope = int((layer_idx+1) % 4 == 0)\n","\n","        # 构造QKV的线型投影层。外加一个output的线型投影层\n","        # 作用：把每个 token 的 hidden state 从维度 hidden_size 映射到 num_attention_heads * head_dim，然后 reshape 为 (B, L, H, D)。\n","        self.q_proj = nn.Linear(config.hidden_size, config.num_attention_heads*self.head_dim, bias=False)\n","        # KV层因为共享缓存，因此假设num_key_value_heads为8，而head_dim为128，则K和V的维度为8*128=4096，节约计算成本\n","        self.k_proj = nn.Linear(config.hidden_size, config.num_key_value_heads*self.head_dim, bias=False)\n","        self.v_proj = nn.Linear(config.hidden_size, config.num_key_value_heads*self.head_dim, bias=False)\n","        self.o_proj = nn.Linear(config.num_attention_heads*self.head_dim, config.hidden_size, bias=False)\n","\n","        if self.config.use_qk_norm and self.use_rope:\n","            # 对Q和K执行L2归一化\n","            self.qk_norm = Llama4TextL2Norm()\n","        else:\n","            self.qk_norm = None\n","\n","    def _repeat_kv(self, hidden_states, n_rep):\n","\n","        ### Add Extra Dimension to Repeat Over ###\n","        ### (B x H x L x E) -> (B x H x 1 x L x E) -> (B x H x n_rep x L x E) -> (B x H*n_rep x L x E)\n","\n","        # 因为KV缓存加速计算，而KV的head数量只有8个，而Q使用的num_attention_heads有40个，因此，要对KV进行复制，40//8=5次\n","        # 获取初始维度\n","        batch, heads, seq_len, embed_dim = hidden_states.shape\n","        #  expand: (B, H, n_rep, L, E) → 重复 n_rep 次，但不复制内存\n","        hidden_states = hidden_states[:, :, None, :, :].expand(batch, heads, n_rep, seq_len, embed_dim)\n","        # reshape：把 H 和 n_rep 合并，得到 (B, H * n_rep, L, E)\n","        hidden_states = hidden_states.reshape(batch, heads*n_rep, seq_len, embed_dim)\n","\n","        return hidden_states\n","\n","    def forward(self,\n","                hidden_states,\n","                position_embeddings=None,\n","                attention_mask=None,\n","                past_key_value=None, # this is a Cache Object\n","                cache_position=None):\n","\n","        ### Get Shape of Tensor (without Embed dims) ###\n","        # 提取输入数据的除emb以外的形状\n","        input_shape = hidden_states.shape[:-1]\n","\n","        ### Create a Shape Tuple (-1 for num heads in the future) ###\n","        # 准备将数据变成(batch_size, seq_len, num_heads, head_dim)形状\n","        hidden_shape = (*input_shape, -1, self.head_dim)\n","\n","        ### Split Embed Dim by Heads ###\n","        # 将输入数据拆分成QKV，并且形状与(batch_size, seq_len, num_heads, head_dim)一致\n","        # 初始为(batch, seq_len, hidden_size)  ->  (batch_size, seq_len, num_heads, head_dim)，其中初始的hidden_size变为num_heads * head_dim\n","        query_states = self.q_proj(hidden_states).reshape(hidden_shape)\n","        key_states = self.k_proj(hidden_states).view(hidden_shape)\n","        # 因为要做Q和K的矩阵乘法，因此要进行转置。\n","        value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1,2)\n","\n","        ### Apply RoPE to Query and Key ###\n","        # 将旋转位置计算加入进attention\n","        if self.use_rope:\n","            query_states, key_states = apply_rotary_emb(query_states, key_states, position_embeddings.to(query_states.device))\n","\n","        ### L2 Norm ###\n","        # 对Q和K进行L2归一化\n","        # 这种方法来源于llama2\n","        # 归一化后，Attention 得分只依赖于方向（角度），更像是余弦相似度。\n","        if self.qk_norm is not None:\n","            query_states = self.qk_norm(query_states)\n","            key_states = self.qk_norm(key_states)\n","\n","        ### Temperature Tuning (on layers not using rope) ###\n","        ### Not total sure how they came up with this as the scaling factor in the ###\n","        ### Paper they referenced https://arxiv.org/abs/2501.19399\n","        ### was just S log(N) where S was some learnable parameter\n","\n","        ### Here was their reasoning:\n","        ### \"We are applying temperature tuning (https://arxiv.org/abs/2501.19399) to NoPE layers, where\n","        ### the inference-time temperature tuning function is customized to not affect short context\n","        ### while working at very long context\"\n","\n","        # 对Q的states进行温度调节\n","        # 可以注意一下这个类的这个属性：self.use_rope = int((layer_idx+1) % 4 == 0) ,根据不同的layer_id，每4层应用一次ROPE。\n","\n","        # 以下是Nope的部分，即，不使用位置编码器。\n","        # cache_position 是一个表示位置的张量，用来记录当前处理的 token 在序列中的位置。\n","        # unsqueeze(0) 是在第一个维度上增加一个新的维度，让它变成二维张量，形状从 [seq_len] 变成 [1, seq_len]\n","        # expand(hidden_states.shape[0], -1)：将 cache_position 张量在hidden_states的第一个维度进行扩展，即batch_size上进行扩展（重复），-1表示保持其他维度不变。\n","        cache_position = cache_position.unsqueeze(0).expand(hidden_states.shape[0],-1)\n","        # 当不使用rope时\n","        if self.attn_temperature_tuning and not self.use_rope: # 这个参数不明白：attn_temperature_tuning\n","            # 对于查询向量query_states进行温度调节\n","            # 首先cache_position的形状是：(batch_size, seq_len)，转换成浮点数加一，相当于下标从1开始，然后除以温度缩放的最小尺度，对结果的每一个元素进行向下取整，结果再加一，乘以注意力缩放因子，再加一\n","            # 这样得到的attn_scales会根据序列中token的不同位置，来调整注意力缩放因子。\n","            # 个人觉得，这个地方绝对是一个优化的点。\n","            attn_scales = (\n","                torch.log(torch.floor((cache_position.float() + 1.0) / self.floor_scale) + 1.0) * self.attn_scale + 1.0\n","            )\n","\n","            # 重塑attn_scales的形状，input_shape的形状为(batch_size, seq_len),转换成：(batch_size, seq_len，1，1)的形状\n","            # 这样，attn_scales 就可以正确地与 query_states 中的每个 token 进行广播\n","            attn_scales = attn_scales.view((*input_shape, 1, 1))\n","            query_states = (query_states * attn_scales).to(query_states.dtype)\n","\n","        ### Flip the Head and Seq Len Dimensions ###\n","        ### (B x L x H x D) -> (B x H x L x D)\n","        # 将Q和K在第二，三维度进行转置，方便后续的计算\n","        query_states = query_states.transpose(1,2)\n","        key_states = key_states.transpose(1,2)\n","\n","        ### Update Key Value Cache ###\n","        # past_key_value是一个缓存对象，需要更新key的状态向量和v的状态向量，以及神经网络层id\n","        if past_key_value is not None:\n","            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx)\n","\n","        ### Grouped Query Attention ###\n","\n","        ### Step 1: Repeat Keys/Values Heads to match the Query Heads\n","        ### Query: (B x Attention Heads x L x E)\n","        ### Key: (B x KV Heads x L x E)\n","        ### Value: (B x KV Heads x L x E)\n","\n","        # 将K和V的头数与Q进行对齐，因此需要重复 config.num_attention_heads // config.num_key_value_heads次\n","        key_states = self._repeat_kv(key_states, self.num_key_value_groups)\n","        value_states = self._repeat_kv(value_states, self.num_key_value_groups)\n","\n","        ### Step 2: Compute Attention Weights ###\n","        # Q和K矩阵做点积，再乘以缩放因子，根号下dk，self.scaling = self.head_dim **-0.5\n","        attn_weights = torch.matmul(query_states, key_states.transpose(2,3)) * self.scaling\n","\n","        ### Step 3: Apply Attention Mask (add large negative numbers to masked positions) ###\n","        ### Also we crop out attention mask only upto the tokens we need ###\n","\n","        # 注意力机制掩码，此处需要后面传入掩码矩阵\n","        if attention_mask is not None:\n","\n","            ### Crop Attetion Mask to only include upto the number of key/value tokens we have to attend to ###\n","            # key_states.shape[-2] 为seq_len ,在掩码矩阵的最后一个维度，选择序列长度的数值\n","            causal_mask = attention_mask[:, :, :, :key_states.shape[-2]]\n","\n","            ### Add Causal Mask to Weights ###\n","            # 将掩码矩阵和attn矩阵的元素按位置相加\n","            attn_weights = attn_weights + causal_mask\n","\n","        ### Standard Attention ###\n","        # 执行注意力机制后面的计算：经过softmax层，再将结果与V做点积，得到的结果在第二、三维度变回原装，即：(batch_size, seq_len, num_heads, head_dim)\n","        attn_weights = nn.functional.softmax(attn_weights.float(), dim=-1).to(query_states.dtype)\n","        attn_output = torch.matmul(attn_weights, value_states)\n","        attn_output = attn_output.transpose(1,2)\n","\n","        ### Final Projection ###\n","        # (batch_size, seq_len, num_heads, head_dim) 转换成为 (batch_size, seq_len, num_heads*head_dim)\n","        attn_output = attn_output.flatten(2)\n","        # 输出最终结果之前，经过线型层变换一下，多注意力头合并。\n","        attn_output = self.o_proj(attn_output)\n","\n","        return attn_output\n","\n"]},{"cell_type":"code","execution_count":13,"id":"b3144858","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3144858","executionInfo":{"status":"ok","timestamp":1746490670832,"user_tz":-480,"elapsed":47,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"3f8fb73f-3df3-4a31-9b0c-de4bbfc29365"},"outputs":[{"output_type":"stream","name":"stdout","text":["['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'attention_chunk_size', 'attention_dropout', 'attn_scale', 'attn_temperature_tuning', 'bos_token_id', 'eos_token_id', 'floor_scale', 'head_dim', 'hidden_size', 'intermediate_size', 'intermediate_size_mlp', 'max_position_embeddings', 'no_rope_layer_interval', 'num_attention_heads', 'num_experts_per_tok', 'num_hidden_layers', 'num_key_value_heads', 'num_local_experts', 'pad_token_id', 'rms_norm_eps', 'rope_theta', 'use_qk_norm', 'vocab_size']\n"]}],"source":["a=Llama4TextConfig()\n","print(dir(a))"]},{"cell_type":"code","execution_count":14,"id":"fb49f51e","metadata":{"id":"fb49f51e","executionInfo":{"status":"ok","timestamp":1746490670833,"user_tz":-480,"elapsed":2,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 单个llamaBlock实现\n","class Llama4TextDecoderLayer(nn.Module):\n","\n","    def __init__(self, config, layer_idx):\n","        super(Llama4TextDecoderLayer, self).__init__()\n","\n","        self.layer_idx = layer_idx\n","        self.hidden_size = config.hidden_size\n","        self.self_attn = Llama4TextAttention(config, layer_idx)\n","        self.use_chunked_attention = int((layer_idx+1) % 4 != 0)\n","        self.feed_forward = Llama4TextMoe(config)\n","        self.input_layernorm = Llama4TextRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n","        self.post_attention_layernorm = Llama4TextRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n","\n","    def forward(self,\n","                hidden_states,\n","                attention_mask,\n","                chunk_causal_mask,\n","                past_key_value,\n","                cache_position,\n","                position_embeddings):\n","\n","        residual = hidden_states\n","\n","        ### Normalize ###\n","        # RMSNorm\n","        hidden_states = self.input_layernorm(hidden_states)\n","\n","        ### Did you pass in chunked attention mask? Then use it if enabled! ###\n","        # 是否使用分块注意力机制\n","        if self.use_chunked_attention and chunk_causal_mask is not None:\n","            attention_mask = chunk_causal_mask\n","\n","        ### Compute Attention ###\n","        # 计算注意力机制\n","        attention_states = self.self_attn(\n","                hidden_states=hidden_states,\n","                position_embeddings=position_embeddings,\n","                attention_mask=attention_mask,\n","                past_key_value=past_key_value, # this is a Cache Object\n","                cache_position=cache_position\n","        )\n","\n","        ### Residual Connection ###\n","        # 将注意力机制计算的结果覆盖到原隐藏层向量矩阵，按元素相加。（残差连接）\n","        hidden_states = residual + attention_states\n","\n","        ### MOE Layer ###\n","        # 用MOE层替换传统的FFN层\n","        residual = hidden_states\n","        hidden_states = self.post_attention_layernorm(hidden_states)\n","        hidden_states = self.feed_forward(hidden_states)\n","        # 残差连接\n","        hidden_states = residual + hidden_states.view(residual.shape)\n","\n","        return hidden_states"]},{"cell_type":"code","execution_count":15,"id":"02f610ca","metadata":{"id":"02f610ca","executionInfo":{"status":"ok","timestamp":1746490670891,"user_tz":-480,"elapsed":59,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 组装Llama的文本模型\n","class Llama4TextModel(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Llama4TextModel, self).__init__()\n","\n","        self.config = config\n","        # <PAD> token的id\n","        self.padding_idx = config.pad_token_id\n","        # 词表大小\n","        self.vocab_sie = config.vocab_size\n","\n","        # 文本token嵌入，把词表中的词映射成固定长度向量\n","        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=self.padding_idx)\n","\n","        # LlamaBlock的堆叠层数\n","        self.layers = nn.ModuleList(\n","            [\n","                Llama4TextDecoderLayer(config, layer_idx)\n","                for layer_idx in range(config.num_hidden_layers)\n","            ]\n","        )\n","        # 实例化RMS对象\n","        self.norm = Llama4TextRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n","        # 实例化旋转位置编码器对象\n","        self.rotary_emb = Llama4TextRotaryEmbedding(config)\n","\n","    def forward(self,\n","                input_ids=None,\n","                input_embeds=None,\n","                attention_mask=None,\n","                position_ids=None,\n","                past_key_values=None,\n","                cache_position=None):\n","\n","        ### Set up Key/Value Cache if it doesnt exist ###\n","        # KVchche不存在，则创建一个对象\n","        if past_key_values is None:\n","            past_key_values = Cache(self.config)\n","\n","        ### Get Input Embeddings ###\n","        # 将输入映射成为向量\n","        if input_embeds is None:\n","            hidden_states = self.embed_tokens(input_ids)\n","        else:\n","            hidden_states = input_embeds\n","\n","        ### Set up Cache Position ###\n","        # 如果Nope的位置张量cache_position为空。\n","        if cache_position is None:\n","            # past_key_values 是缓存对象，它存储了之前步骤的键值对（key-value pairs）。get_seq_len() 获取缓存中已经处理过的 token 数量，表示已经处理过的序列长度。\n","            past_seen_tokens = past_key_values.get_seq_len()\n","            # 生成一个连续的整数序列，表示当前输入中每个 token 在整个序列中的位置\n","            # 如果之前缓存的token为0，则生成seq_len长度的序列，作为nope的位置表示\n","            cache_position = torch.arange(past_seen_tokens, past_seen_tokens+hidden_states.shape[1], device=hidden_states.device)\n","\n","        ### Setup Position Ids ###\n","        if position_ids is None:\n","            # cache_position的形状为(seq_len)，需要在第一个维度也就是0维度添加一个维度，变成（batch，seq_len）的形状\n","            position_ids = cache_position.unsqueeze(0)\n","\n","        ### Update Causal Mask ###\n","        # 注意力机制掩码的计算\n","        causal_mask, chunked_attention_mask = self._update_causal_mask(\n","            attention_mask, hidden_states, cache_position\n","        )\n","\n","        ### Compute Rotary Embeddings ###\n","        # 旋转位置编码的计算\n","        freq_cis = self.rotary_emb(hidden_states, position_ids)\n","\n","        ### Pass Through Layers ###\n","        # LlamaBlock堆叠组成的model，对于每一个Block，需要将数据经过每一个Vlock前向传播进行计算，得到的隐藏层的向量，传递到下一层。\n","        for layer in self.layers:\n","            hidden_states = layer(hidden_states,\n","                                  attention_mask,\n","                                  chunked_attention_mask if chunked_attention_mask is not None else causal_mask,\n","                                  past_key_values,\n","                                  cache_position,\n","                                  freq_cis)\n","        # 当数据经过了所有的Block层，对隐藏层的状态向量进行归一化。\n","        hidden_states = self.norm(hidden_states)\n","\n","        # 返回前向传播的结果，以及用于减少计算量的kv缓存，用于下一次迭代不用重复计算。\n","        return hidden_states, past_key_values\n","\n","\n","    # 注意力的掩码张量计算包含了两个计算：一个是自回归的因果掩码，一个是分块掩码。\n","    # 首先是因果掩码\n","    def _prepare_4d_causal_attention_mask_with_cache_position(\n","            self,\n","            attention_mask,\n","            sequence_length,\n","            cache_position,\n","            batch_size,\n","            dtype,\n","            device\n","    ):\n","        # 如果掩码张量已存在，则直接使用\n","        if attention_mask is not None:\n","            causal_mask = attention_mask\n","\n","        else:\n","\n","            ### Create a Causal Mask ###\n","            # torch.finfo(dtype).min是用来获取指定数据类型（dtype）的最小值\n","            # 如：min_float32=-3.4028235e+38，而min_float64:-1.7976931348623157e+308\n","            min_dtype = torch.finfo(dtype).min\n","\n","            # 创建一个形状为(seq*seq)大小的用最小值min_type填充的矩阵\n","            # 为啥要用极小值？ 因为在做softmax的时候，如果用0填充，则softmax后，e^0 = 1，掩码的部分不会变小，而是获得更多的关注。\n","            # 而使用极小值，会在经过softmax后，掩码的值更趋近于0\n","            causal_mask = torch.full(\n","                (sequence_length, sequence_length), fill_value=min_dtype, dtype=dtype, device=device\n","            )\n","\n","            ### If we have more than one token, we need causal mask, so current token doesnt look forward ###\n","            # 应用因果掩码，右上三角\n","            if sequence_length != 1:\n","                causal_mask = torch.triu(causal_mask, diagonal=1)\n","\n","            ### Check Wherever our Sequence index is longer than the cache positions ###\n","            ### If a Query is BEFORE the Key/Value Cache Index, then the Query would have ###\n","            ### to look into the future which is not allowed and needs to be masked! ###\n","\n","            # 作用，生成一个掩码，保证每个token只能看到自己之前的单词，没办法看到自己之后的单词。\n","            # 这个代码的思路很有意思，生成seq_len长度的数，与位置缓存中的内容进行比对，返回True或False。\n","            causal_mask *= torch.arange(sequence_length, device=device) > cache_position.to(device).reshape(-1,1)\n","\n","            ### Add Extra Dimension to causal Mask (4 dimensions, with placeholder for head dim) ###\n","            # 将掩码张量添加batch_size，在第一维度，变为(batch_size, 1, sequence_length, sequence_length)\n","            causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)\n","\n","            ### If Attention mask is Not None, then add causal and attention mask together ###\n","            if attention_mask is not None:\n","                # 如果attention_mask不为空，则克隆一份作为causal_mask，原始causal_mask不被修改\n","                causal_mask = causal_mask.clone()\n","\n","                ### Only keep upto length in attention mask ###\n","                # 掩码的长度为最后一个维度\n","                mask_length = attention_mask.shape[-1]\n","                #causal_mask[:, :, :, :mask_length] 和 attention_mask[:, None, None, :] 进行了加法，生成了一个新的 padding_mask，它包含了 causal_mask 和 attention_mask 合并后的结果。\n","                padding_mask = causal_mask[:, :, :, :mask_length] + attention_mask[:, None, None, :].to(device)\n","                # 生成bool值的掩码，当padding mask中的元素值为0的地方会被设置为True，否则为False\n","                padding_mask = (padding_mask==0)\n","                # masked_fill会将padding mask中为True的元素，使用极小值min dtype进行替换\n","                causal_mask[:,:,:,:mask_length] = causal_mask[:,:,:,:mask_length].masked_fill(padding_mask, min_dtype)\n","\n","            return causal_mask\n","    # 创建分块注意力掩码\n","    def _create_chunked_attention_mask(\n","            self,\n","            attention_chunk_size,\n","            start,\n","            end,\n","            device\n","    ):\n","\n","        ### Create Blocks in the Chunk Sizes you want ###\n","        # tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2],\n","        #         [0, 0, 0, 1, 1, 1, 2, 2, 2],\n","        #         [0, 0, 0, 1, 1, 1, 2, 2, 2],\n","        #         [1, 1, 1, 0, 0, 0, 1, 1, 1],\n","        #         [1, 1, 1, 0, 0, 0, 1, 1, 1],\n","        #         [1, 1, 1, 0, 0, 0, 1, 1, 1],\n","        #         [2, 2, 2, 1, 1, 1, 0, 0, 0],\n","        #         [2, 2, 2, 1, 1, 1, 0, 0, 0],\n","        #         [2, 2, 2, 1, 1, 1, 0, 0, 0]])\n","\n","        # 按照块的大小attention_chunk_size进行创建掩码，创建两个长度相同的矩阵，分别在第1维度和第二维度添加新维度，分别与attention_chunk_size做整除，然后使用abs做两个张量之间差的绝对值\n","        # 行向量和列向量通过广播机制进行相减，得到的结果为 (end-start)*(end-start)形状的矩阵\n","        block_pos = torch.abs(\n","            (torch.arange(start, end).unsqueeze(0)//attention_chunk_size) -\n","            (torch.arange(start, end).unsqueeze(1)//attention_chunk_size)\n","        )\n","\n","        ### Do computation again but without absolute value or division to get token positions###\n","        # tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n","        #         [-1,  0,  1,  2,  3,  4,  5,  6,  7],\n","        #         [-2, -1,  0,  1,  2,  3,  4,  5,  6],\n","        #         [-3, -2, -1,  0,  1,  2,  3,  4,  5],\n","        #         [-4, -3, -2, -1,  0,  1,  2,  3,  4],\n","        #         [-5, -4, -3, -2, -1,  0,  1,  2,  3],\n","        #         [-6, -5, -4, -3, -2, -1,  0,  1,  2],\n","        #         [-7, -6, -5, -4, -3, -2, -1,  0,  1],\n","        #         [-8, -7, -6, -5, -4, -3, -2, -1,  0]])\n","\n","        #构造一个二维的“位置差值矩阵”，行列相减，广播计算。\n","        tok_pos = torch.arange(start, end).unsqueeze(0) - torch.arange(start,end).unsqueeze(1)\n","\n","        ### Wherever our block pos is 0 (our chunks) and our tok_pos is negative (causal mask) We want those ###\n","        # 上面两个矩阵做运算，最终结果：\n","        # tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n","                # [1, 1, 0, 0, 0, 0, 0, 0, 0],\n","                # [1, 1, 1, 0, 0, 0, 0, 0, 0],\n","                # [0, 0, 0, 1, 0, 0, 0, 0, 0],\n","                # [0, 0, 0, 1, 1, 0, 0, 0, 0],\n","                # [0, 0, 0, 1, 1, 1, 0, 0, 0],\n","                # [0, 0, 0, 0, 0, 0, 1, 0, 0],\n","                # [0, 0, 0, 0, 0, 0, 1, 1, 0],\n","                # [0, 0, 0, 0, 0, 0, 1, 1, 1]])\n","\n","        mask = (block_pos==0) & (tok_pos<=0)\n","        # 此处计算，相当于既保留因果掩码，同时也使用分块注意力机制来减少计算量。\n","        return mask.to(device)\n","\n","    def _update_causal_mask(self,\n","                            attention_mask,\n","                            input_tensor,\n","                            cache_position):\n","\n","        ### Get Sequence Length and Attention Chunk Size ###\n","        ### Honestly the attention chunk size is huge (over 8000)\n","        ### we could probably skip this as we are just creating a\n","        ### minimal version here but lets just do it anyway!\n","\n","        #序列长度\n","        seq_len = input_tensor.shape[1]\n","        # 获取分块注意力机制分多少块\n","        attention_chunk_size = self.config.attention_chunk_size\n","\n","        ### Get the Starting and Ending Position from Cache ###\n","        # 从位置信息缓存获取开始的token位置，默认batch_size为1\n","        start_cache_pos = cache_position[0]\n","\n","        ### Two Checks: Is our First Cache Position greater than our chunk size:\n","        # 确认当前是否超过attention_chunk_size，如果超过attention_chunk_size，代表不是第一个注意力掩码的分块，有可能是第二个或者更后面的chunk\n","        cond1 = start_cache_pos >= attention_chunk_size\n","\n","        ### Is our first cache in the first chunk, but with the seq_len it rolls over to the second chunk ###\n","        # 判断当前序列是否跨越了一个 attention chunk 的边界。这个条件的设计在分块注意力中非常关键，用于决定是否要做特殊的 mask 处理。\n","        #\n","        cond2 = (start_cache_pos < attention_chunk_size) & (start_cache_pos + seq_len > attention_chunk_size)\n","\n","        ### This is just a fancy if/else\n","        ### If cond1 is True then key_length = attention_chunk_size + seq_len - 1\n","        ### elif cond1 is false, then if cond2 is True then key_length = start_cache_pos + seq_len\n","        ### else key_length = attention_chunk_size\n","\n","        # 当cond1 == True，表示整个序列起始位置就在 chunk 边界 之后，即你已经处在 chunk 1、chunk 2 等之后的块中。key 长度设为attention_chunk_size + seq_len - 1，key 范围涵盖前一个 chunk 全部，加上当前序列的长度，-1是为了对其index\n","        # 当cond1 == False 且 cond2 == True，起始位置在第一个 chunk，但本次序列 跨越 chunk 边界。start_cache_pos + seq_len。表示从起始位置向前看，只允许看到从头到当前序列末尾的所有位置。\n","        # 当cond1 == False 且 cond2 == False，key的长度为attention_chunk_size，表示 attention mask 只允许关注第一个 chunk 内的 token。\n","        key_length = torch.where(\n","            cond1,\n","            attention_chunk_size + seq_len - 1,\n","            torch.where(cond2, start_cache_pos + seq_len, attention_chunk_size),\n","        )\n","\n","        # 对于短序列，采用完整的因果注意力机制掩码。\n","        causal_mask = self._prepare_4d_causal_attention_mask_with_cache_position(\n","            attention_mask,\n","            sequence_length=seq_len,\n","            cache_position=cache_position,\n","            batch_size=input_tensor.shape[0],\n","            dtype=input_tensor.dtype,\n","            device=input_tensor.device\n","        )\n","\n","        # 对于长序列，使用分块注意力机制掩码，同时需要注意keylength的条件\n","        chunked_attention_mask = None\n","        if seq_len > self.config.attention_chunk_size:\n","            chunked_attention_mask = self._create_chunked_attention_mask(\n","                self.config.attention_chunk_size,\n","                start=start_cache_pos,\n","                end=start_cache_pos+key_length,\n","                device=input_tensor.device\n","            )\n","\n","            ### Mask only valid wherever attention mask is valid ###\n","            # 避免 padding 位置参与 attention。\n","            # 即使 chunked 允许 attend 某些位置，如果 attention_mask 说这些是 padding，也强行掩掉。\n","            chunked_attention_mask = chunked_attention_mask & attention_mask\n","\n","            ### Add dimensions and fill with -inf ###\n","\n","            # 最终结果chunked_attention_mask是形状 [1, 1, T_q, T_k]、类型为 float16/32 的张量\n","            chunked_attention_mask = (\n","                    # 将 chunked_attention_mask的shape 从 [T_q, T_k] 扩展为 [1, 1, T_q, T_k]\n","                    chunked_attention_mask[None, None, :, :]\n","                    .to(input_tensor.dtype)\n","                    # 掩码填充最小值，如果chunked_attention_mask元素为True则填充float的极小值作为掩码\n","                    .masked_fill(chunked_attention_mask, torch.finfo(input_tensor.dtype).min)\n","                )\n","\n","        return causal_mask, chunked_attention_mask"]},{"cell_type":"code","execution_count":16,"id":"c12c49dd","metadata":{"id":"c12c49dd","executionInfo":{"status":"ok","timestamp":1746490670895,"user_tz":-480,"elapsed":6,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 组装Llama4的文本模型\n","class Llama4ForCausalLM(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Llama4ForCausalLM, self).__init__()\n","\n","        self.model = Llama4TextModel(config)\n","        self.vocab_size = config.vocab_size\n","        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n","\n","    def forward(self,\n","                input_ids=None,\n","                input_embeds=None,\n","                attention_mask=None,\n","                position_ids=None,\n","                past_key_values=None):\n","\n","        outputs, past_key_values = self.model(\n","            input_ids,\n","            input_embeds,\n","            attention_mask=attention_mask,\n","            position_ids=position_ids,\n","            past_key_values=past_key_values\n","        )\n","\n","        logits = self.lm_head(outputs)\n","\n","        return logits, past_key_values"]},{"cell_type":"markdown","id":"bdb6bf2a","metadata":{"id":"bdb6bf2a"},"source":["## 测试一下Llama4的文本模型"]},{"cell_type":"code","execution_count":17,"id":"3ffc31d1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ffc31d1","executionInfo":{"status":"ok","timestamp":1746490676006,"user_tz":-480,"elapsed":5110,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"348205ec-b930-48f1-c6de-4defc4c9ce41"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0.0025, -0.5620, -0.4375,  ...,  0.0257, -1.3712,  0.6038],\n","          [-0.4009, -0.6086, -0.9811,  ..., -0.9013, -1.4526, -2.3509],\n","          [-0.4687, -0.8944, -0.8898,  ..., -0.7189, -0.2462, -1.4411],\n","          [ 0.1211, -0.0571, -0.7741,  ..., -1.2612,  1.8620, -1.0120]],\n"," \n","         [[ 0.2321,  0.9299, -0.7671,  ..., -0.8695, -1.0250, -0.5184],\n","          [ 0.4672,  2.0185, -0.6713,  ..., -0.0438,  0.4846,  0.7930],\n","          [ 0.0340, -0.1279,  1.6977,  ...,  1.6885, -0.1599, -0.1174],\n","          [ 0.4492,  0.1601, -0.9914,  ..., -1.2002, -1.2287, -0.5730]]],\n","        grad_fn=<MulBackward0>),\n"," DyanmicCache(Num_Layers: 2 | Cached Tokens: 4))"]},"metadata":{},"execution_count":17}],"source":["config=Llama4TextConfig(hidden_size=768,\n","                        intermediate_size=768*4,\n","                        intermediate_size_mlp=768*4,\n","                        num_hidden_layers=2,\n","                        num_attention_heads=12,\n","                        num_key_value_heads=3\n","                        )\n","rope=Llama4TextRotaryEmbedding(config)\n","rand=torch.randn(2,4,768,dtype=torch.float32)\n","position_ids=torch.arange(0,4).unsqueeze(0).expand(2,-1)\n","freqs_cis=rope(rand,position_ids)\n","layer=Llama4TextModel(config)\n","layer(input_embeds=rand)"]},{"cell_type":"markdown","id":"5e5f4b1e","metadata":{"id":"5e5f4b1e"},"source":["## Llama4文本部分的训练，保存，以及推理"]},{"cell_type":"code","execution_count":18,"id":"66bfd3f7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66bfd3f7","executionInfo":{"status":"ok","timestamp":1746490676494,"user_tz":-480,"elapsed":489,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"2ba9dcac-cd27-4999-d787-ded748466ebe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('xiyouji.txt', <http.client.HTTPMessage at 0x7dbc2fdba850>)"]},"metadata":{},"execution_count":18}],"source":["import urllib.request\n","# 下载《西游记》文本\n","url = \"https://raw.githubusercontent.com/mc112611/PI-ka-pi/main/xiyouji.txt\"\n","file_name = \"xiyouji.txt\"\n","urllib.request.urlretrieve(url, file_name)"]},{"cell_type":"code","execution_count":19,"id":"2df711c7","metadata":{"id":"2df711c7","executionInfo":{"status":"ok","timestamp":1746490676741,"user_tz":-480,"elapsed":292,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 加载文本\n","with open(file_name, 'r', encoding='utf-8') as f:\n","    lines = f.read()\n","\n","# 构建字符表\n","vocab = sorted(list(set(lines)))\n","itos = {i: ch for i, ch in enumerate(vocab)}\n","stoi = {ch: i for i, ch in enumerate(vocab)}\n","\n","# 编码函数\n","def encode(s):\n","    return [stoi[ch] for ch in s]\n","\n","def decode(indices):\n","    return ''.join([itos[i] for i in indices])\n","\n","# 转为 Tensor 数据集\n","dataset = torch.tensor(encode(lines), dtype=torch.long)\n"]},{"cell_type":"code","execution_count":20,"id":"ff893c97","metadata":{"id":"ff893c97","executionInfo":{"status":"ok","timestamp":1746490676760,"user_tz":-480,"elapsed":17,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 修改一下参数，否则太大了\n","\n","config_test = Llama4TextConfig(\n","    vocab_size=len(vocab),\n","    hidden_size=256,\n","    intermediate_size=512,\n","    intermediate_size_mlp=512,\n","    num_hidden_layers=4,\n","    num_attention_heads=4,\n","    num_key_value_heads=2,\n","    head_dim=32,\n","    max_position_embeddings=128 * 16,\n","    rms_norm_eps=1e-5,\n","    pad_token_id=1000,\n","    bos_token_id=1,\n","    eos_token_id=2,\n","    rope_theta=500000,\n","    attention_dropout=0.0,\n","    num_experts_per_tok=1,\n","    num_local_experts=4,\n","    use_qk_norm=True,\n","    no_rope_layer_interval=4,\n","    attention_chunk_size=512,\n","    attn_temperature_tuning=4,\n","    floor_scale=8192,\n","    attn_scale=0.1\n",")\n"]},{"cell_type":"code","execution_count":21,"id":"04d85db9","metadata":{"id":"04d85db9","executionInfo":{"status":"ok","timestamp":1746490676768,"user_tz":-480,"elapsed":1,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import urllib.request\n","import random\n","import os\n","\n","def create_dataloader(dataset, batch_size, context_window, split='train'):\n","    train_size = int(0.8 * len(dataset))\n","    val_size = int(0.1 * len(dataset))\n","\n","    if split == 'train':\n","        data = dataset[:train_size]\n","    elif split == 'val':\n","        data = dataset[train_size:train_size + val_size]\n","    else:\n","        data = dataset[train_size + val_size:]\n","\n","    print(f\"Preparing {split} set with {len(data)} characters...\")\n","\n","    # tqdm 包裹 unfold 显示进度\n","    data = tqdm(data.unfold(0, context_window, 1), desc=\"Sliding window\")\n","    data = torch.stack(list(data))\n","    return DataLoader(TensorDataset(data), batch_size=batch_size, shuffle=True)\n"]},{"cell_type":"code","execution_count":22,"id":"b607c6a6","metadata":{"id":"b607c6a6","executionInfo":{"status":"ok","timestamp":1746490681258,"user_tz":-480,"elapsed":4489,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["device = torch.device(\"cpu\")\n","\n","embedding = nn.Embedding(config_test.vocab_size, config_test.hidden_size).to(device)\n","model = Llama4TextModel(config_test).to(device)\n","output_head = nn.Linear(config_test.hidden_size, config_test.vocab_size).to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(\n","    list(model.parameters()) + list(embedding.parameters()) + list(output_head.parameters()), lr=1e-4\n",")\n"]},{"cell_type":"markdown","id":"263425f0","metadata":{"id":"263425f0"},"source":["## GPU训练\n","\n","为了使用GPU进行训练，我们需要将KVcache，model，embedding放到显卡上"]},{"cell_type":"code","execution_count":23,"id":"6349cd35","metadata":{"id":"6349cd35","executionInfo":{"status":"ok","timestamp":1746490681262,"user_tz":-480,"elapsed":2,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["class Cache:\n","    \"\"\"\n","    KV Cache Method that is close to the Huggingface DynamicCache\n","    https://github.com/huggingface/transformers/blob/main/src/transformers/cache_utils.py\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        ### Counter for Number of Tokens in Cache ###\n","        # 缓存的token数量（计数器）\n","        self._seen_tokens = 0\n","\n","        ### Key/Value Cache (List of Tensor, where list is over model layers) ###\n","        self.key_cache = [torch.tensor([]) for _ in range(config.num_hidden_layers)]\n","        self.value_cache = [torch.tensor([]) for _ in range(config.num_hidden_layers)]\n","\n","    def __repr__(self):\n","        return f\"DyanmicCache(Num_Layers: {len(self.key_cache)} | Cached Tokens: {self.key_cache[0].shape[2]})\"\n","\n","    def update(self, key_states, value_states, layer_idx):\n","        ### Only iterate num tokens seen on the first layer ###\n","        ### key_states (B x H x L x E)\n","        ### value_states (B x H x L x E)\n","\n","        if layer_idx == 0:\n","            self._seen_tokens += key_states.shape[-2]\n","\n","        ### Append New key/Value states to key/value cache ###\n","        self.key_cache[layer_idx] = torch.cat([self.key_cache[layer_idx], key_states], dim=-2)\n","        self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], value_states], dim=-2)\n","\n","        # 返回更新后的缓存\n","        return self.key_cache[layer_idx], self.value_cache[layer_idx]\n","\n","    def get_seq_len(self, layer_idx=0):\n","        return self.key_cache[layer_idx].shape[-2] if self.key_cache[layer_idx].numel() != 0 else 0\n","\n","    # 新增：设备迁移方法\n","    def to(self, device):\n","        self.key_cache = [key.to(device) for key in self.key_cache]\n","        self.value_cache = [value.to(device) for value in self.value_cache]\n","        return self\n"]},{"cell_type":"code","execution_count":24,"id":"b867f770","metadata":{"id":"b867f770","executionInfo":{"status":"ok","timestamp":1746490681302,"user_tz":-480,"elapsed":25,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":["# 组装Llama的文本模型\n","class Llama4TextModel(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Llama4TextModel, self).__init__()\n","\n","        self.config = config\n","        # <PAD> token的id\n","        self.padding_idx = config.pad_token_id\n","        # 词表大小\n","        self.vocab_sie = config.vocab_size\n","\n","        # 文本token嵌入，把词表中的词映射成固定长度向量\n","        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=self.padding_idx)\n","\n","        # LlamaBlock的堆叠层数\n","        self.layers = nn.ModuleList(\n","            [\n","                Llama4TextDecoderLayer(config, layer_idx)\n","                for layer_idx in range(config.num_hidden_layers)\n","            ]\n","        )\n","        # 实例化RMS对象\n","        self.norm = Llama4TextRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n","        # 实例化旋转位置编码器对象\n","        self.rotary_emb = Llama4TextRotaryEmbedding(config)\n","\n","    def forward(self,\n","                input_ids=None,\n","                input_embeds=None,\n","                attention_mask=None,\n","                position_ids=None,\n","                past_key_values=None,\n","                cache_position=None):\n","\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        ### Set up Key/Value Cache if it doesnt exist ###\n","        if past_key_values is None:\n","            # 确保 KVcache 在相同设备上\n","            past_key_values = Cache(self.config).to(device)\n","\n","        ### Get Input Embeddings ###\n","        if input_embeds is None:\n","            # 确保 embedding 层输出在相同设备上\n","            hidden_states = self.embed_tokens(input_ids).to(device)\n","        else:\n","            # 确保 input_embeds 在相同设备上\n","            hidden_states = input_embeds.to(device)\n","\n","        ### Set up Cache Position ###\n","        if cache_position is None:\n","            past_seen_tokens = past_key_values.get_seq_len()\n","            cache_position = torch.arange(past_seen_tokens, past_seen_tokens+hidden_states.shape[1], device=hidden_states.device)\n","            # 确保 cache_position 在相同设备上\n","            cache_position = cache_position.to(device)\n","\n","        ### Setup Position Ids ###\n","        # 确保 position_ids 在相同设备上\n","        if position_ids is None:\n","            position_ids = cache_position.unsqueeze(0).to(device)\n","\n","        ### Update Causal Mask ###\n","        causal_mask, chunked_attention_mask = self._update_causal_mask(\n","            attention_mask, hidden_states, cache_position\n","        )\n","\n","        ### Compute Rotary Embeddings ###\n","        freq_cis = self.rotary_emb(hidden_states, position_ids)\n","\n","        ### Pass Through Layers ###\n","        for layer in self.layers:\n","            hidden_states = layer(hidden_states,\n","                                attention_mask,\n","                                chunked_attention_mask if chunked_attention_mask is not None else causal_mask,\n","                                past_key_values,\n","                                cache_position,\n","                                freq_cis)\n","\n","        hidden_states = self.norm(hidden_states)\n","\n","        return hidden_states, past_key_values\n","\n","\n","\n","\n","    # 注意力的掩码张量计算包含了两个计算：一个是自回归的因果掩码，一个是分块掩码。\n","    # 首先是因果掩码\n","    def _prepare_4d_causal_attention_mask_with_cache_position(\n","            self,\n","            attention_mask,\n","            sequence_length,\n","            cache_position,\n","            batch_size,\n","            dtype,\n","            device\n","    ):\n","        # 如果掩码张量已存在，则直接使用\n","        if attention_mask is not None:\n","            causal_mask = attention_mask\n","\n","        else:\n","\n","            ### Create a Causal Mask ###\n","            # torch.finfo(dtype).min是用来获取指定数据类型（dtype）的最小值\n","            # 如：min_float32=-3.4028235e+38，而min_float64:-1.7976931348623157e+308\n","            min_dtype = torch.finfo(dtype).min\n","\n","            # 创建一个形状为(seq*seq)大小的用最小值min_type填充的矩阵\n","            # 为啥要用极小值？ 因为在做softmax的时候，如果用0填充，则softmax后，e^0 = 1，掩码的部分不会变小，而是获得更多的关注。\n","            # 而使用极小值，会在经过softmax后，掩码的值更趋近于0\n","            causal_mask = torch.full(\n","                (sequence_length, sequence_length), fill_value=min_dtype, dtype=dtype, device=device\n","            )\n","\n","            ### If we have more than one token, we need causal mask, so current token doesnt look forward ###\n","            # 应用因果掩码，右上三角\n","            if sequence_length != 1:\n","                causal_mask = torch.triu(causal_mask, diagonal=1)\n","\n","            ### Check Wherever our Sequence index is longer than the cache positions ###\n","            ### If a Query is BEFORE the Key/Value Cache Index, then the Query would have ###\n","            ### to look into the future which is not allowed and needs to be masked! ###\n","\n","            # 作用，生成一个掩码，保证每个token只能看到自己之前的单词，没办法看到自己之后的单词。\n","            # 这个代码的思路很有意思，生成seq_len长度的数，与位置缓存中的内容进行比对，返回True或False。\n","            causal_mask *= torch.arange(sequence_length, device=device) > cache_position.to(device).reshape(-1,1)\n","\n","            ### Add Extra Dimension to causal Mask (4 dimensions, with placeholder for head dim) ###\n","            # 将掩码张量添加batch_size，在第一维度，变为(batch_size, 1, sequence_length, sequence_length)\n","            causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)\n","\n","            ### If Attention mask is Not None, then add causal and attention mask together ###\n","            if attention_mask is not None:\n","                # 如果attention_mask不为空，则克隆一份作为causal_mask，原始causal_mask不被修改\n","                causal_mask = causal_mask.clone()\n","\n","                ### Only keep upto length in attention mask ###\n","                # 掩码的长度为最后一个维度\n","                mask_length = attention_mask.shape[-1]\n","                #causal_mask[:, :, :, :mask_length] 和 attention_mask[:, None, None, :] 进行了加法，生成了一个新的 padding_mask，它包含了 causal_mask 和 attention_mask 合并后的结果。\n","                padding_mask = causal_mask[:, :, :, :mask_length] + attention_mask[:, None, None, :].to(device)\n","                # 生成bool值的掩码，当padding mask中的元素值为0的地方会被设置为True，否则为False\n","                padding_mask = (padding_mask==0)\n","                # masked_fill会将padding mask中为True的元素，使用极小值min dtype进行替换\n","                causal_mask[:,:,:,:mask_length] = causal_mask[:,:,:,:mask_length].masked_fill(padding_mask, min_dtype)\n","\n","            return causal_mask\n","    # 创建分块注意力掩码\n","    def _create_chunked_attention_mask(\n","            self,\n","            attention_chunk_size,\n","            start,\n","            end,\n","            device\n","    ):\n","\n","        ### Create Blocks in the Chunk Sizes you want ###\n","        # tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2],\n","        #         [0, 0, 0, 1, 1, 1, 2, 2, 2],\n","        #         [0, 0, 0, 1, 1, 1, 2, 2, 2],\n","        #         [1, 1, 1, 0, 0, 0, 1, 1, 1],\n","        #         [1, 1, 1, 0, 0, 0, 1, 1, 1],\n","        #         [1, 1, 1, 0, 0, 0, 1, 1, 1],\n","        #         [2, 2, 2, 1, 1, 1, 0, 0, 0],\n","        #         [2, 2, 2, 1, 1, 1, 0, 0, 0],\n","        #         [2, 2, 2, 1, 1, 1, 0, 0, 0]])\n","\n","        # 按照块的大小attention_chunk_size进行创建掩码，创建两个长度相同的矩阵，分别在第1维度和第二维度添加新维度，分别与attention_chunk_size做整除，然后使用abs做两个张量之间差的绝对值\n","        # 行向量和列向量通过广播机制进行相减，得到的结果为 (end-start)*(end-start)形状的矩阵\n","        block_pos = torch.abs(\n","            (torch.arange(start, end).unsqueeze(0)//attention_chunk_size) -\n","            (torch.arange(start, end).unsqueeze(1)//attention_chunk_size)\n","        )\n","\n","        ### Do computation again but without absolute value or division to get token positions###\n","        # tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n","        #         [-1,  0,  1,  2,  3,  4,  5,  6,  7],\n","        #         [-2, -1,  0,  1,  2,  3,  4,  5,  6],\n","        #         [-3, -2, -1,  0,  1,  2,  3,  4,  5],\n","        #         [-4, -3, -2, -1,  0,  1,  2,  3,  4],\n","        #         [-5, -4, -3, -2, -1,  0,  1,  2,  3],\n","        #         [-6, -5, -4, -3, -2, -1,  0,  1,  2],\n","        #         [-7, -6, -5, -4, -3, -2, -1,  0,  1],\n","        #         [-8, -7, -6, -5, -4, -3, -2, -1,  0]])\n","\n","        #构造一个二维的“位置差值矩阵”，行列相减，广播计算。\n","        tok_pos = torch.arange(start, end).unsqueeze(0) - torch.arange(start,end).unsqueeze(1)\n","\n","        ### Wherever our block pos is 0 (our chunks) and our tok_pos is negative (causal mask) We want those ###\n","        # 上面两个矩阵做运算，最终结果：\n","        # tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n","                # [1, 1, 0, 0, 0, 0, 0, 0, 0],\n","                # [1, 1, 1, 0, 0, 0, 0, 0, 0],\n","                # [0, 0, 0, 1, 0, 0, 0, 0, 0],\n","                # [0, 0, 0, 1, 1, 0, 0, 0, 0],\n","                # [0, 0, 0, 1, 1, 1, 0, 0, 0],\n","                # [0, 0, 0, 0, 0, 0, 1, 0, 0],\n","                # [0, 0, 0, 0, 0, 0, 1, 1, 0],\n","                # [0, 0, 0, 0, 0, 0, 1, 1, 1]])\n","\n","        mask = (block_pos==0) & (tok_pos<=0)\n","        # 此处计算，相当于既保留因果掩码，同时也使用分块注意力机制来减少计算量。\n","        return mask.to(device)\n","\n","    def _update_causal_mask(self,\n","                            attention_mask,\n","                            input_tensor,\n","                            cache_position):\n","\n","        ### Get Sequence Length and Attention Chunk Size ###\n","        ### Honestly the attention chunk size is huge (over 8000)\n","        ### we could probably skip this as we are just creating a\n","        ### minimal version here but lets just do it anyway!\n","\n","        #序列长度\n","        seq_len = input_tensor.shape[1]\n","        # 获取分块注意力机制分多少块\n","        attention_chunk_size = self.config.attention_chunk_size\n","\n","        ### Get the Starting and Ending Position from Cache ###\n","        # 从位置信息缓存获取开始的token位置，默认batch_size为1\n","        start_cache_pos = cache_position[0]\n","\n","        ### Two Checks: Is our First Cache Position greater than our chunk size:\n","        # 确认当前是否超过attention_chunk_size，如果超过attention_chunk_size，代表不是第一个注意力掩码的分块，有可能是第二个或者更后面的chunk\n","        cond1 = start_cache_pos >= attention_chunk_size\n","\n","        ### Is our first cache in the first chunk, but with the seq_len it rolls over to the second chunk ###\n","        # 判断当前序列是否跨越了一个 attention chunk 的边界。这个条件的设计在分块注意力中非常关键，用于决定是否要做特殊的 mask 处理。\n","        #\n","        cond2 = (start_cache_pos < attention_chunk_size) & (start_cache_pos + seq_len > attention_chunk_size)\n","\n","        ### This is just a fancy if/else\n","        ### If cond1 is True then key_length = attention_chunk_size + seq_len - 1\n","        ### elif cond1 is false, then if cond2 is True then key_length = start_cache_pos + seq_len\n","        ### else key_length = attention_chunk_size\n","\n","        # 当cond1 == True，表示整个序列起始位置就在 chunk 边界 之后，即你已经处在 chunk 1、chunk 2 等之后的块中。key 长度设为attention_chunk_size + seq_len - 1，key 范围涵盖前一个 chunk 全部，加上当前序列的长度，-1是为了对其index\n","        # 当cond1 == False 且 cond2 == True，起始位置在第一个 chunk，但本次序列 跨越 chunk 边界。start_cache_pos + seq_len。表示从起始位置向前看，只允许看到从头到当前序列末尾的所有位置。\n","        # 当cond1 == False 且 cond2 == False，key的长度为attention_chunk_size，表示 attention mask 只允许关注第一个 chunk 内的 token。\n","        key_length = torch.where(\n","            cond1,\n","            attention_chunk_size + seq_len - 1,\n","            torch.where(cond2, start_cache_pos + seq_len, attention_chunk_size),\n","        )\n","\n","        # 对于短序列，采用完整的因果注意力机制掩码。\n","        causal_mask = self._prepare_4d_causal_attention_mask_with_cache_position(\n","            attention_mask,\n","            sequence_length=seq_len,\n","            cache_position=cache_position,\n","            batch_size=input_tensor.shape[0],\n","            dtype=input_tensor.dtype,\n","            device=input_tensor.device\n","        )\n","\n","        # 对于长序列，使用分块注意力机制掩码，同时需要注意keylength的条件\n","        chunked_attention_mask = None\n","        if seq_len > self.config.attention_chunk_size:\n","            chunked_attention_mask = self._create_chunked_attention_mask(\n","                self.config.attention_chunk_size,\n","                start=start_cache_pos,\n","                end=start_cache_pos+key_length,\n","                device=input_tensor.device\n","            )\n","\n","            ### Mask only valid wherever attention mask is valid ###\n","            # 避免 padding 位置参与 attention。\n","            # 即使 chunked 允许 attend 某些位置，如果 attention_mask 说这些是 padding，也强行掩掉。\n","            chunked_attention_mask = chunked_attention_mask & attention_mask\n","\n","            ### Add dimensions and fill with -inf ###\n","\n","            # 最终结果chunked_attention_mask是形状 [1, 1, T_q, T_k]、类型为 float16/32 的张量\n","            chunked_attention_mask = (\n","                    # 将 chunked_attention_mask的shape 从 [T_q, T_k] 扩展为 [1, 1, T_q, T_k]\n","                    chunked_attention_mask[None, None, :, :]\n","                    .to(input_tensor.dtype)\n","                    # 掩码填充最小值，如果chunked_attention_mask元素为True则填充float的极小值作为掩码\n","                    .masked_fill(chunked_attention_mask, torch.finfo(input_tensor.dtype).min)\n","                )\n","\n","        return causal_mask, chunked_attention_mask"]},{"cell_type":"code","execution_count":29,"id":"b885acdd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731,"referenced_widgets":["62ba97d31ddf469792c20fdee2b7b629","043e40d605054ef0a182d844c6476675","596a133159fd4c6685fbbc8024cb9f23","5d96e5142162408bbcc5ec6fab2ab954","6640c1e6aaa64dbaabdaef7f79e87ba1","b49f50e3e10f46b5a0b55550b18e5654","01c4076452974ff8ac8b87a06921f265","809d29e1b15948b894a5c1844db71696","e56ffdd174e64d80b0084b69388e01c3","df034abf115c4b5a9bd9ac09c327c0b7","e797541c2dd144259e4e57fc70c7c44e","1e44e668d5cd43278d11483d59d0c239","e8f7bb50933b4a0c848cec41801f92da","6513bcfe0ec24a78807ab2c39e9d7831","0252c3f162344bce93d23578f1f0a9c8","28ade5519eca4d07b2726e9558b1541a","0a1a5cf0e18941f28bc027128eb78ae0","9214d124496940448005896ec41fa847","e6d1ec41c5bb49ca9473f8f39977e638","42c958c345be40fc901da51abcd70fec","5e9b0fe2580d4c5db0a18f8d976e5b14","b46cceb378b148a3967b435ba7f7c873"]},"id":"b885acdd","executionInfo":{"status":"ok","timestamp":1746494199511,"user_tz":-480,"elapsed":752225,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"d8f8a522-889d-4991-c533-02950b9645e9"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Preparing train set with 526638 characters...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62ba97d31ddf469792c20fdee2b7b629","version_major":2,"version_minor":0},"text/plain":["Sliding window:   0%|          | 0/526511 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"," Epoch 1/1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e44e668d5cd43278d11483d59d0c239","version_major":2,"version_minor":0},"text/plain":["Training:   0%|          | 0/4114 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["✅ Epoch 1 finished | 🔺 Average Loss: 4.2095\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import torch\n","from torch import nn, optim\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import numpy as np\n","\n","# 设置设备\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# 初始化模型组件\n","embedding = nn.Embedding(config_test.vocab_size, config_test.hidden_size).to(device)\n","model = Llama4TextModel(config_test).to(device)\n","output_head = nn.Linear(config_test.hidden_size, config_test.vocab_size).to(device)\n","\n","# 损失函数与优化器\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(\n","    list(model.parameters()) + list(embedding.parameters()) + list(output_head.parameters()),\n","    lr=1e-4\n",")\n","\n","# 超参数\n","epochs = 1\n","batch_size = 128\n","context_window = 128\n","log_every = 100  # 每 log_every 个 batch 记录一次损失\n","\n","train_loader = create_dataloader(dataset, batch_size, context_window, split='train')\n","\n","# 存储每次记录时的 batch 编号和对应的 loss\n","logged_batches = []\n","logged_losses = []\n","\n","# ==== 训练循环 ====\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    print(f\"\\n Epoch {epoch+1}/{epochs}\")\n","    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n","\n","    for batch_idx, (inputs,) in enumerate(progress_bar):\n","        inputs = inputs.long().to(device)\n","        targets = inputs[:, 1:].contiguous()\n","        inputs = inputs[:, :-1].contiguous()\n","\n","        input_embeds = embedding(inputs)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_embeds=input_embeds)\n","        hidden_states = outputs[0]\n","        logits = output_head(hidden_states)\n","\n","        logits = logits.view(-1, logits.size(-1))\n","        targets = targets.view(-1)\n","\n","        loss = loss_fn(logits, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        # 控制记录频率\n","        if (batch_idx + 1) % log_every == 0:\n","            avg_batch_loss = total_loss / (batch_idx + 1)\n","            logged_batches.append(batch_idx + 1)\n","            logged_losses.append(avg_batch_loss)\n","\n","        # tqdm 实时更新\n","        progress_bar.set_postfix({\n","            \"Batch Loss\": f\"{loss.item():.4f}\",\n","            \"Avg Loss\": f\"{total_loss / (batch_idx + 1):.4f}\"\n","        })\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(f\"✅ Epoch {epoch+1} finished | 🔺 Average Loss: {avg_loss:.4f}\")\n","\n","# ==== 绘图 ====\n","plt.figure(figsize=(12, 6))\n","plt.plot(logged_batches, logged_losses, marker='o', linestyle='-', color='blue', label='Avg Loss')\n","plt.title('Loss Curve During Training', fontsize=16)\n","plt.xlabel('Batch Index', fontsize=12)\n","plt.ylabel('Average Loss', fontsize=12)\n","plt.xticks(fontsize=10)\n","plt.yticks(fontsize=10)\n","plt.grid(True, linestyle='--', alpha=0.5)\n","plt.legend()\n","plt.tight_layout()\n","plt.savefig('loss_curve_smooth.png')\n","plt.show()\n"]},{"cell_type":"code","execution_count":26,"id":"243c4d7e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"243c4d7e","executionInfo":{"status":"ok","timestamp":1746492233119,"user_tz":-480,"elapsed":19,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"7c2bc702-5bd4-47a2-d18d-b6015408158e"},"outputs":[{"output_type":"stream","name":"stdout","text":["模型已保存！\n"]}],"source":["save_path = \"./llama4text_model.pth\"\n","torch.save({\n","    \"model_state\": model.state_dict(),\n","    \"embedding_state\": embedding.state_dict(),\n","    \"output_head_state\": output_head.state_dict(),\n","    \"vocab\": vocab,\n","    \"config\": config_test.__dict__\n","}, save_path)\n","print(\"模型已保存！\")\n"]},{"cell_type":"code","execution_count":27,"id":"020f20a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"020f20a1","executionInfo":{"status":"ok","timestamp":1746492233284,"user_tz":-480,"elapsed":164,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"8cb5e2ad-65f1-4265-fbb9-c6e0b579e474"},"outputs":[{"output_type":"stream","name":"stdout","text":["🔄 正在加载模型权重...\n","✅ 模型加载完毕\n"]}],"source":["print(\"正在加载模型权重...\")\n","checkpoint = torch.load(\"llama4text_model.pth\", map_location=device)\n","\n","vocab = checkpoint['vocab']\n","itos = {i: ch for i, ch in enumerate(vocab)}\n","stoi = {ch: i for i, ch in enumerate(vocab)}\n","\n","config_test_generate = Llama4TextConfig(**checkpoint[\"config\"])\n","embedding = nn.Embedding(config_test_generate.vocab_size, config_test_generate.hidden_size).to(device)\n","model = Llama4TextModel(config_test_generate).to(device)\n","output_head = nn.Linear(config_test_generate.hidden_size, config_test_generate.vocab_size).to(device)\n","\n","embedding.load_state_dict(checkpoint['embedding_state'])\n","model.load_state_dict(checkpoint['model_state'])\n","output_head.load_state_dict(checkpoint['output_head_state'])\n","\n","print(\"模型加载完毕咯\")\n"]},{"cell_type":"code","execution_count":32,"id":"81972f4b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":114,"referenced_widgets":["ac5ad658f69f4592b95abf7e140c34cd","91b2f9ca65b140e1bec6dd12abbfe2ae","1f9f72ce5b3c4c62835ae17a5b48ac92","273ac28160a740efb61e0d30c6a00778","84c0541530ef4f009ac9238a3990f567","c4d7861f60194cbeb946c4ce4f22bf61","9ee1140c14094c10bc052386239c6046","636ca9d535c94c3bbb1d8b60ae31ca8c","f4a62dcddca54f15b22713850489531d","0c32000458ad46e88030f0cfa7b156bf","6543268fa48c45eca7bc4367ba948f57"]},"id":"81972f4b","executionInfo":{"status":"ok","timestamp":1746494348957,"user_tz":-480,"elapsed":1247,"user":{"displayName":"chi ma","userId":"09061819115802133413"}},"outputId":"05bd89d1-8a66-46e0-f793-23d6da0feec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["🌱 初始字符: 蛋\n"]},{"output_type":"display_data","data":{"text/plain":["Generating:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac5ad658f69f4592b95abf7e140c34cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"蛋产森罗刹内观看经偈王、五五百岁经文牒咒》径直裰门外公主婚阳峪杀—————————————————————————————————————————————————————————————————————"},"metadata":{}}],"source":["import torch.nn.functional as F\n","from IPython.display import display, Markdown\n","\n","def sample_next_token(logits, top_k=10, top_p=0.9, temperature=1.0):\n","    logits = logits / temperature\n","    probs = F.softmax(logits, dim=-1)\n","\n","    # Top-k 筛选\n","    if top_k is not None:\n","        top_k = min(top_k, probs.size(-1))\n","        values, indices = torch.topk(probs, top_k)\n","        probs_zero = torch.zeros_like(probs).scatter(-1, indices, values)\n","        probs = probs_zero / probs_zero.sum()\n","\n","    # Top-p 筛选\n","    if top_p is not None:\n","        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n","        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n","        cutoff = cumulative_probs > top_p\n","        if torch.any(cutoff):\n","            last_index = torch.where(cutoff)[0][0] + 1\n","            sorted_probs = sorted_probs[:last_index]\n","            sorted_indices = sorted_indices[:last_index]\n","        probs = torch.zeros_like(probs).scatter(-1, sorted_indices, sorted_probs)\n","        probs = probs / probs.sum()\n","\n","    return torch.multinomial(probs, num_samples=1).item()\n","\n","def generate_text(start_text='', length=200, top_k=10, top_p=0.9, temperature=1.0):\n","    if not start_text:\n","        start_text = random.choice(vocab)\n","    print(f\"🌱 初始字符: {start_text}\")\n","\n","    input_ids = torch.tensor([stoi[c] for c in start_text], dtype=torch.long).unsqueeze(0).to(device)\n","\n","    for _ in tqdm(range(length), desc=\"Generating\"):\n","        input_embeds = embedding(input_ids)\n","        with torch.no_grad():\n","            outputs = model(input_embeds=input_embeds)\n","        hidden_states = outputs[0]\n","        logits = output_head(hidden_states[:, -1, :])  # 只取最后一个 token 的 logits\n","\n","        next_id = sample_next_token(logits.squeeze(), top_k=top_k, top_p=top_p, temperature=temperature)\n","        input_ids = torch.cat([input_ids, torch.tensor([[next_id]], device=device)], dim=1)\n","\n","    generated = decode(input_ids[0].tolist())\n","    return generated\n","\n","\n","generated = generate_text(length=100, top_k=3, top_p=0.9, temperature=1.7)\n","display(Markdown(generated))\n"]},{"cell_type":"code","execution_count":31,"id":"555f1b3c","metadata":{"id":"555f1b3c","executionInfo":{"status":"ok","timestamp":1746494345536,"user_tz":-480,"elapsed":2,"user":{"displayName":"chi ma","userId":"09061819115802133413"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"62ba97d31ddf469792c20fdee2b7b629":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_043e40d605054ef0a182d844c6476675","IPY_MODEL_596a133159fd4c6685fbbc8024cb9f23","IPY_MODEL_5d96e5142162408bbcc5ec6fab2ab954"],"layout":"IPY_MODEL_6640c1e6aaa64dbaabdaef7f79e87ba1"}},"043e40d605054ef0a182d844c6476675":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b49f50e3e10f46b5a0b55550b18e5654","placeholder":"​","style":"IPY_MODEL_01c4076452974ff8ac8b87a06921f265","value":"Sliding window: 100%"}},"596a133159fd4c6685fbbc8024cb9f23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_809d29e1b15948b894a5c1844db71696","max":526511,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e56ffdd174e64d80b0084b69388e01c3","value":526511}},"5d96e5142162408bbcc5ec6fab2ab954":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df034abf115c4b5a9bd9ac09c327c0b7","placeholder":"​","style":"IPY_MODEL_e797541c2dd144259e4e57fc70c7c44e","value":" 526511/526511 [00:01&lt;00:00, 437538.58it/s]"}},"6640c1e6aaa64dbaabdaef7f79e87ba1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49f50e3e10f46b5a0b55550b18e5654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01c4076452974ff8ac8b87a06921f265":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"809d29e1b15948b894a5c1844db71696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56ffdd174e64d80b0084b69388e01c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df034abf115c4b5a9bd9ac09c327c0b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e797541c2dd144259e4e57fc70c7c44e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e44e668d5cd43278d11483d59d0c239":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8f7bb50933b4a0c848cec41801f92da","IPY_MODEL_6513bcfe0ec24a78807ab2c39e9d7831","IPY_MODEL_0252c3f162344bce93d23578f1f0a9c8"],"layout":"IPY_MODEL_28ade5519eca4d07b2726e9558b1541a"}},"e8f7bb50933b4a0c848cec41801f92da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a1a5cf0e18941f28bc027128eb78ae0","placeholder":"​","style":"IPY_MODEL_9214d124496940448005896ec41fa847","value":"Training: 100%"}},"6513bcfe0ec24a78807ab2c39e9d7831":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6d1ec41c5bb49ca9473f8f39977e638","max":4114,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42c958c345be40fc901da51abcd70fec","value":4114}},"0252c3f162344bce93d23578f1f0a9c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e9b0fe2580d4c5db0a18f8d976e5b14","placeholder":"​","style":"IPY_MODEL_b46cceb378b148a3967b435ba7f7c873","value":" 4114/4114 [25:53&lt;00:00,  3.18it/s, Batch Loss=3.2414, Avg Loss=4.2095]"}},"28ade5519eca4d07b2726e9558b1541a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"0a1a5cf0e18941f28bc027128eb78ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9214d124496940448005896ec41fa847":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d1ec41c5bb49ca9473f8f39977e638":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42c958c345be40fc901da51abcd70fec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e9b0fe2580d4c5db0a18f8d976e5b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b46cceb378b148a3967b435ba7f7c873":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac5ad658f69f4592b95abf7e140c34cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91b2f9ca65b140e1bec6dd12abbfe2ae","IPY_MODEL_1f9f72ce5b3c4c62835ae17a5b48ac92","IPY_MODEL_273ac28160a740efb61e0d30c6a00778"],"layout":"IPY_MODEL_84c0541530ef4f009ac9238a3990f567"}},"91b2f9ca65b140e1bec6dd12abbfe2ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4d7861f60194cbeb946c4ce4f22bf61","placeholder":"​","style":"IPY_MODEL_9ee1140c14094c10bc052386239c6046","value":"Generating: 100%"}},"1f9f72ce5b3c4c62835ae17a5b48ac92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_636ca9d535c94c3bbb1d8b60ae31ca8c","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4a62dcddca54f15b22713850489531d","value":100}},"273ac28160a740efb61e0d30c6a00778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c32000458ad46e88030f0cfa7b156bf","placeholder":"​","style":"IPY_MODEL_6543268fa48c45eca7bc4367ba948f57","value":" 100/100 [00:01&lt;00:00, 83.49it/s]"}},"84c0541530ef4f009ac9238a3990f567":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4d7861f60194cbeb946c4ce4f22bf61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ee1140c14094c10bc052386239c6046":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"636ca9d535c94c3bbb1d8b60ae31ca8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4a62dcddca54f15b22713850489531d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c32000458ad46e88030f0cfa7b156bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6543268fa48c45eca7bc4367ba948f57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}